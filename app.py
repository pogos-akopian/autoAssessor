import streamlit as st
import pandas as pd
import time
import altair as alt
from judge_logic import evaluate_with_yandex

# Page Config
st.set_page_config(
    page_title="–ê–≤—Ç–æ–ê—Å–µ—Å—Å–æ—Ä: YandexGPT-as-a-Judge",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Custom CSS for nicer UI
st.markdown("""
<style>
    .stButton>button {
        width: 100%;
        background-color: #fc3f1d; /* Yandex Red/Orange-ish */
        color: white;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #fc3f1d;
    }
</style>
""", unsafe_allow_html=True)


# 1. Sidebar (Global Settings)
st.sidebar.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

demo_mode = st.sidebar.checkbox("–î–µ–º–æ-—Ä–µ–∂–∏–º (Mock)", value=True)

api_key = st.sidebar.text_input("Yandex IAM Token / API Key", type="password", disabled=demo_mode)
folder_id = st.sidebar.text_input("Yandex Folder ID", disabled=demo_mode)
if not demo_mode:
    st.sidebar.caption("Folder ID is required to access YandexGPT resources in your cloud.")

st.sidebar.markdown("---")
st.sidebar.markdown("### üé≠ –ü–µ—Ä—Å–æ–Ω–∞ –°—É–¥—å–∏")
persona_name = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å –æ—Ü–µ–Ω–∫–∏",
    ["Strict Fact-Checker", "Helpful Editor"]
)

if persona_name == "Strict Fact-Checker":
    st.sidebar.info("üßê **Strict Fact-Checker**: –§–æ–∫—É—Å –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç–æ–≤. –ñ–µ—Å—Ç–∫–æ —à—Ç—Ä–∞—Ñ—É–µ—Ç –∑–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏.")
else:
    st.sidebar.info("‚úçÔ∏è **Helpful Editor**: –§–æ–∫—É—Å –Ω–∞ —Å—Ç–∏–ª–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ —Ç–æ–Ω–µ. –¶–µ–Ω–∏—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.")

st.sidebar.markdown("---")
st.sidebar.info("–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –ø–æ 8 –∫—Ä–∏—Ç–µ—Ä–∏—è–º:\n\n1. –ë–µ–∑–≤—Ä–µ–¥–Ω–æ—Å—Ç—å\n2. –î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å\n3. –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å\n4. –ü–æ–ª–Ω–æ—Ç–∞\n5. –õ–∞–∫–æ–Ω–∏—á–Ω–æ—Å—Ç—å\n6. –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å\n7. –£–º–µ—Å—Ç–Ω–æ—Å—Ç—å\n8. –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å")

# Analytics Function
def show_analytics(df):
    st.markdown("### üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –¢–æ–∫–µ–Ω–æ–º–∏–∫–∞")
    
    # 1. Prepare Data
    total = len(df)
    
    # Derive winner column if not present
    if "winner" not in df.columns:
        def get_winner(row):
            sa = row.get("score_a_overall", 0)
            sb = row.get("score_b_overall", 0)
            if sa > sb: return "Model A"
            elif sb > sa: return "Model B"
            else: return "Tie"
        df["winner"] = df.apply(get_winner, axis=1)

    # 2. Key Metrics (Quality)
    model_a_wins = len(df[df["winner"] == "Model A"])
    model_b_wins = len(df[df["winner"] == "Model B"])
    
    win_rate_a = (model_a_wins / total * 100) if total > 0 else 0
    win_rate_b = (model_b_wins / total * 100) if total > 0 else 0
    
    avg_score_a = df["score_a_overall"].mean()
    avg_score_b = df["score_b_overall"].mean()
    
    st.markdown("#### üèÜ –ö–∞—á–µ—Å—Ç–≤–æ –ú–æ–¥–µ–ª–µ–π")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Win Rate (Model A)", f"{win_rate_a:.1f}%")
    m2.metric("Win Rate (Model B)", f"{win_rate_b:.1f}%")
    m3.metric("–°—Ä. –±–∞–ª–ª (Model A)", f"{avg_score_a:.1f}")
    m4.metric("–°—Ä. –±–∞–ª–ª (Model B)", f"{avg_score_b:.1f}")
    
    # 3. Tokenomics
    st.markdown("#### üí∞ –¢–æ–∫–µ–Ω–æ–º–∏–∫–∞")
    
    # Ensure token columns exist and are numeric
    for col in ["input_tokens", "output_tokens", "total_tokens"]:
        if col not in df.columns:
            df[col] = 0
            
    total_input = df["input_tokens"].sum()
    total_output = df["output_tokens"].sum()
    grand_total_tokens = df["total_tokens"].sum()
    
    # Cost Estimation (Mock: 0.40 RUB per 1k tokens combined for simplicity)
    est_cost = (grand_total_tokens / 1000) * 0.40
    
    t1, t2, t3 = st.columns(3)
    t1.metric("Total Tokens", f"{grand_total_tokens:,}")
    t2.metric("Avg Tokens / Query", f"{int(grand_total_tokens / total) if total else 0}")
    t3.metric("Est. Cost (‚ÇΩ)", f"‚ÇΩ{est_cost:.2f}", help="–†–∞—Å—á–µ—Ç–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: 0.40 ‚ÇΩ –∑–∞ 1k —Ç–æ–∫–µ–Ω–æ–≤")
    
    # 4. Charts
    c1, c2 = st.columns(2)
    
    with c1:
        st.caption("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–±–µ–¥")
        winner_counts = df["winner"].value_counts().reset_index()
        winner_counts.columns = ["Winner", "Count"]

        chart = alt.Chart(winner_counts).mark_arc(innerRadius=50).encode(
            theta=alt.Theta(field="Count", type="quantitative"),
            color=alt.Color(field="Winner", type="nominal", scale=alt.Scale(domain=['Model A', 'Model B', 'Tie'], range=['#fc3f1d', '#4a90e2', '#999999'])),
            tooltip=["Winner", "Count"]
        )
        st.altair_chart(chart, use_container_width=True)
        
    with c2:
        st.caption("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º")
        # Prepare data for stacked bar chart: Query Index -> Input, Output
        # Altair needs long format for stacked bars
        
        # Add index column for X-axis
        df_chart = df.reset_index()
        
        token_chart_data = df_chart.melt(id_vars=["index"], value_vars=["input_tokens", "output_tokens"], var_name="Token Type", value_name="Count")
        
        bar_chart = alt.Chart(token_chart_data).mark_bar().encode(
            x=alt.X("index:O", title="–ù–æ–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞"),
            y=alt.Y("Count:Q", title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤"),
            color=alt.Color("Token Type", scale=alt.Scale(domain=['input_tokens', 'output_tokens'], range=['#9CA3AF', '#F59E0B'])),
            tooltip=["index", "Token Type", "Count"]
        )
        st.altair_chart(bar_chart, use_container_width=True)


# Main Title
st.title("‚öñÔ∏è –ê–≤—Ç–æ–ê—Å–µ—Å—Å–æ—Ä: YandexGPT-as-a-Judge")
st.markdown("LLM-as-a-Judge –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ powered by **YandexGPT**.")

# Tabs
tab_single, tab_batch = st.tabs(["üìù –û–¥–∏–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º", "üöÄ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"])

# --- TAB 1: SINGLE MODE ---
with tab_single:
    user_query = st.text_input("–ó–∞–ø—Ä–æ—Å", placeholder="–í—Å—Ç–∞–≤—å—Ç–µ –∑–∞–ø—Ä–æ—Å...")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("–û—Ç–≤–µ—Ç Model A")
        ans_a = st.text_area("–û—Ç–≤–µ—Ç A", height=200, placeholder="–í—Å—Ç–∞–≤—å—Ç–µ –æ—Ç–≤–µ—Ç Model A...")

    with col2:
        st.subheader("–û—Ç–≤–µ—Ç Model B")
        ans_b = st.text_area("–û—Ç–≤–µ—Ç B", height=200, placeholder="–í—Å—Ç–∞–≤—å—Ç–µ –æ—Ç–≤–µ—Ç Model B...")

    # Logic
    if st.button("–û—Ü–µ–Ω–∏—Ç—å!", type="primary", key="btn_single"):
        if not user_query or not ans_a or not ans_b:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –∏ –æ–±–∞ –æ—Ç–≤–µ—Ç–∞.")
        else:
            with st.spinner(f"–ó–∞–ø—Ä–æ—Å –∫ YandexGPT ({persona_name})..."):
                result = evaluate_with_yandex(
                    query=user_query,
                    ans_a=ans_a,
                    ans_b=ans_b,
                    api_key=api_key,
                    folder_id=folder_id,
                    demo_mode=demo_mode,
                    persona_name=persona_name
                )

            if "error" in result:
                st.error(f"Error: {result['error']}")
                if "raw_response" in result:
                    with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å Raw Response"):
                        st.code(result["raw_response"])
            else:
                # Display Results
                st.markdown("---")
                st.success("–û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                
                # Comparison Summary
                st.markdown(f"### üí° –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤–µ—Ä–¥–∏–∫—Ç")
                st.info(result.get('comparison', '–ù–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤–µ—Ä–¥–∏–∫—Ç–∞.'))
                
                # Show Token Usage for Single Mode too
                if "usage" in result:
                    usage = result["usage"]
                    st.caption(f"üí∞ Tokens: {usage.get('totalTokens')} (In: {usage.get('inputTextTokens')}, Out: {usage.get('completionTokens')})")

                res_col1, res_col2 = st.columns(2)
                
                # Helper to display model stats
                def display_model_stats(container, model_key, title):
                    data = result.get(model_key, {})
                    container.markdown(f"## {title}")
                    container.metric("Overall Score", f"{data.get('overall_score', 0)}/10")
                    
                    container.markdown("#### –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ")
                    container.caption(data.get('reasoning', "–ù–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏—è."))
                    
                    container.markdown("#### –ö—Ä–∏—Ç–µ—Ä–∏–∏")
                    scores = data.get('scores', {})
                    for k, v in scores.items():
                        container.progress(v / 10, text=f"{k}: {v}/10")

                with res_col1:
                    display_model_stats(st, "model_a", "Model A")
                
                with res_col2:
                    display_model_stats(st, "model_b", "Model B")

# --- TAB 2: BATCH MODE ---
with tab_batch:
    st.markdown("### –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª")
    st.markdown("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã: `query`, `answer_a`, `answer_b`.")
    
    uploaded_file = st.file_uploader("Upload CSV", type=["csv"])
    
    # Clear state if new file uploaded (optional UX choice, keeping simple for now)
    
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            
            # Validation
            required_cols = {'query', 'answer_a', 'answer_b'}
            if not required_cols.issubset(df.columns):
                st.error(f"–û—à–∏–±–∫–∞: –í CSV —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {required_cols - set(df.columns)}")
            else:
                st.markdown("#### –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):")
                st.dataframe(df.head())
                
                if st.button("–ù–∞—á–∞—Ç—å –ø–∞–∫–µ—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É", type="primary", key="btn_batch"):
                    
                    results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    total_rows = len(df)
                    
                    for index, row in df.iterrows():
                        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏ {index + 1} –∏–∑ {total_rows}...")
                        
                        # Demo mode throttling
                        if demo_mode:
                            time.sleep(0.1)
                        
                        eval_res = evaluate_with_yandex(
                            query=row['query'],
                            ans_a=row['answer_a'],
                            ans_b=row['answer_b'],
                            api_key=api_key,
                            folder_id=folder_id,
                            demo_mode=demo_mode,
                            persona_name=persona_name
                        )
                        
                        # Parse Result for CSV
                        row_result = row.to_dict()
                        if "error" in eval_res:
                            row_result["error"] = eval_res["error"]
                        else:
                            # Model A Stats
                            ma = eval_res.get("model_a", {})
                            row_result["score_a_overall"] = ma.get("overall_score")
                            row_result["reasoning_a"] = ma.get("reasoning")
                            
                            # Model B Stats
                            mb = eval_res.get("model_b", {})
                            row_result["score_b_overall"] = mb.get("overall_score")
                            row_result["reasoning_b"] = mb.get("reasoning")
                            
                            row_result["comparison"] = eval_res.get("comparison")
                            
                            # Token Usage
                            usage = eval_res.get("usage", {})
                            row_result["input_tokens"] = int(usage.get("inputTextTokens", 0))
                            row_result["output_tokens"] = int(usage.get("completionTokens", 0))
                            row_result["total_tokens"] = int(usage.get("totalTokens", 0))
                            
                        results.append(row_result)
                        progress_bar.progress((index + 1) / total_rows)
                    
                    status_text.text("–ì–æ—Ç–æ–≤–æ!")
                    progress_bar.empty()
                    
                    # Store in Session State
                    result_df = pd.DataFrame(results)
                    st.session_state['batch_results'] = result_df
                    
                # Display Results from Session State
                if 'batch_results' in st.session_state:
                    result_df = st.session_state['batch_results']
                    
                    with st.expander("üìä –û—Ç—á–µ—Ç –æ–± –æ—Ü–µ–Ω–∫–µ", expanded=True):
                        st.success("–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                        
                        # Analytics
                        show_analytics(result_df)
                        
                        st.markdown("### –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è")
                        st.dataframe(result_df)
                        
                        csv = result_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
                            data=csv,
                            file_name="evaluation_results.csv",
                            mime="text/csv",
                        )
                    
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
